{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkhfring/cosc419-notes/blob/main/week6/name_generation_wavenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mEF05xtbHwp"
      },
      "source": [
        "## makemore: part 5 (building a WaveNet)\n",
        "\n",
        "[DeepMind blog post from 2016](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imJHt_hUcMGe"
      },
      "source": [
        "<img title=\"a title\" alt=\"Alt text\" src=\"https://lh3.googleusercontent.com/AjY4_VKcnFaDEvHUVapAqLT_YUhoTt04WK0NNA-pNHAfSdDQr-PmyEUNiVuitogTiWN7EEWn8pci9hTwKX_qlokNXkPOB-J7FU6kzW2s5Fcm-LibCA=w1232-rw\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7lDFibCgbHwr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htdQCnUPbhS9",
        "outputId": "cdc730bb-84ed-457e-8f3a-1ca1e34a1be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 21:30:45--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-11-19 21:30:45 (9.85 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylW9Ir3GbHws",
        "outputId": "6d0ff1e9-f499-4f9e-f12d-8592570bc6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPwi-_rEbHwt",
        "outputId": "7cc39129-305b-4eef-94b4-c77753134f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j8JdduA3bHwu"
      },
      "outputs": [],
      "source": [
        "# shuffle up the words\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcrfsUG_bHwu",
        "outputId": "5a9e3aa4-6196-4bac-c913-7d988f069b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aFDMks6bHwv",
        "outputId": "7c286950-b937-49e0-b9b3-fbb38be1a606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... --> y\n",
            "..y --> u\n",
            ".yu --> h\n",
            "yuh --> e\n",
            "uhe --> n\n",
            "hen --> g\n",
            "eng --> .\n",
            "... --> d\n",
            "..d --> i\n",
            ".di --> o\n",
            "dio --> n\n",
            "ion --> d\n",
            "ond --> r\n",
            "ndr --> e\n",
            "dre --> .\n",
            "... --> x\n",
            "..x --> a\n",
            ".xa --> v\n",
            "xav --> i\n",
            "avi --> e\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Because of gradient vanishing and gradient explosion, we need to normalise the output of each layer using a technique, which is called batch normalization.\n",
        "\n",
        "- **The vanishing gradient problem occurs when the gradients used to update the weights during backpropagation become extremely small, effectively stopping the weights from being updated. This problem is particularly prevalent in neural networks with many layers when using activation functions like tanh.**\n",
        "\n",
        "Properties of tanh:\n",
        "- The tanh function maps inputs to the range (-1, 1).\n",
        "- \tIts derivative (gradient) is given by  1 - tanh(x)^2 .\n",
        "- When x is very large or very small, tanh(x) saturates, approaching 1 or -1, and its derivative becomes close to 0.\n",
        "\n",
        "\n",
        "### Batch Normalization helps alleviate the vanishing gradient problem by maintaining the scale of activations in a stable range, which ensures that gradients do not shrink excessively as they propagate through the network"
      ],
      "metadata": {
        "id": "Y1-s6gIwcxo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iUFEY7m081YH"
      },
      "outputs": [],
      "source": [
        "# This block of code is not necessary to undrestand\n",
        "class Linear:\n",
        "\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# The implementation of BatchNorm is not important for our course\n",
        "class BatchNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      if x.ndim == 2:\n",
        "        dim = 0\n",
        "      elif x.ndim == 3:\n",
        "        dim = (0,1)\n",
        "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
        "      xvar = x.var(dim, keepdim=True) # batch variance\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dKxvxfd9TQM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4k6FYb59Zuo"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42); # seed rng for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHGH2IR_-3kk",
        "outputId": "cf36065a-415e-48c9-aca8-d540b9934eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "C = torch.randn((vocab_size, n_embd))\n",
        "layers = [\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "]\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s8-ud2NBwLO",
        "outputId": "bf7b9cb7-6c89-4ad0-afb7-e9932f7ea945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/  30000: 3.3268\n",
            "  10000/  30000: 2.1307\n",
            "  20000/  30000: 1.9557\n"
          ]
        }
      ],
      "source": [
        "max_steps = 30000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # (32, 8, 10)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (32, 80)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "  layer.training = False"
      ],
      "metadata": {
        "id": "AFVRXQxRmlZ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[Xb] # (32, 8, 10)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (32, 80)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlwVtcJYmwRA",
        "outputId": "fe143de6-4a80-430c-9ea8-d068e6d89a56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.974465250968933\n",
            "val 1.974465250968933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      emb = C[torch.tensor([context])] # (32, 8, 10)\n",
        "      x = emb.view(emb.shape[0], -1) # concat into (32, 80)\n",
        "      for layer in layers:\n",
        "        x = layer(x)\n",
        "      logits = x\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPHMIu3Ino70",
        "outputId": "d453ed7d-7447-4b4a-8aaf-61c692cc63d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "axen.\n",
            "helles.\n",
            "jeck.\n",
            "niven.\n",
            "cadoriah.\n",
            "kurol.\n",
            "khrian.\n",
            "lephane.\n",
            "liliany.\n",
            "mari.\n",
            "kamansy.\n",
            "nughni.\n",
            "api.\n",
            "chanlevin.\n",
            "dra.\n",
            "marshendrin.\n",
            "jamkand.\n",
            "beszaieb.\n",
            "yas.\n",
            "hogrten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Embedding:\n",
        "\n",
        "  def __init__(self, num_embeddings, embedding_dim):\n",
        "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "  def __call__(self, IX):\n",
        "    self.out = self.weight[IX]\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight]\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Flatten:\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x.view(x.shape[0], -1)\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "60awaRf4pXUL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "layers = [\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "]\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = [p for layer in layers for p in layer.parameters()]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvhsoCRTqHov",
        "outputId": "849e6ecf-245a-46be-a57e-0bc4b95aaa99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 30000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  x = Xb\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tmzq-TOqBij",
        "outputId": "2eb91f23-500a-42aa-b8f0-a2c0539310e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/  30000: 3.3013\n",
            "  10000/  30000: 1.7760\n",
            "  20000/  30000: 1.9924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential:\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    # get parameters of all layers and stretch them out into one list\n",
        "    return [p for layer in self.layers for p in layer.parameters()]"
      ],
      "metadata": {
        "id": "TK7lVCrKsRTb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VtRvqxAsd61",
        "outputId": "61ca4a2c-c145-42bc-fc57-f9fa5f0d2f71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 30000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "\n",
        "  x = model(Xb)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUIqR0C9sw0j",
        "outputId": "e3555464-a290-4d6d-a10f-3cdb480b52de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/  30000: 3.4395\n",
            "  10000/  30000: 2.5585\n",
            "  20000/  30000: 2.1585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  layer.training = False"
      ],
      "metadata": {
        "id": "Gh0GQRUetRZ5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3kXuQ-xtTvz",
        "outputId": "1d441d0c-0508-4d5a-e413-c9b7339b5699"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.1833858489990234\n",
            "val 2.208043098449707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tKAC4-8-aKqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0bb40d-c915-471f-a3bf-bf7d30b1d7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fre.\n",
            "ten.\n",
            "preh.\n",
            "jegancelexine.\n",
            "korgaeliansrel.\n",
            "kritz.\n",
            "kio.\n",
            "rith.\n",
            "aalbria.\n",
            "winleya.\n",
            "kaosha.\n",
            "rosyn.\n",
            "lore.\n",
            "bailyn.\n",
            "laniyogan.\n",
            "shael.\n",
            "tihaan.\n",
            "rashi.\n",
            "dricheamarth.\n",
            "prie.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      logits = model(torch.tensor([context]))\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Experiments with the entier dataset\n"
      ],
      "metadata": {
        "id": "Ed-kUJTaWfZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfqNwhrDw5Ge",
        "outputId": "87de9231-4678-42da-8b18-bb9b4090ded7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 8]) torch.Size([182625])\n",
            "torch.Size([22655, 8]) torch.Size([22655])\n",
            "torch.Size([22866, 8]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbVZ_N34xEMB",
        "outputId": "755931ca-f890-4c89-a910-ca3060dda951"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........ --> y\n",
            ".......y --> u\n",
            "......yu --> h\n",
            ".....yuh --> e\n",
            "....yuhe --> n\n",
            "...yuhen --> g\n",
            "..yuheng --> .\n",
            "........ --> d\n",
            ".......d --> i\n",
            "......di --> o\n",
            ".....dio --> n\n",
            "....dion --> d\n",
            "...diond --> r\n",
            "..diondr --> e\n",
            ".diondre --> .\n",
            "........ --> x\n",
            ".......x --> a\n",
            "......xa --> v\n",
            ".....xav --> i\n",
            "....xavi --> e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRlwqMmExalt",
        "outputId": "21aac8b9-b7ff-4e0f-b228-ad07154c8ab0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 50000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "\n",
        "  x = model(Xb)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhGBbRCyxjcC",
        "outputId": "c86d0aa8-2d01-4418-e600-f45cb251fd0e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/  50000: 3.2577\n",
            "  10000/  50000: 1.8404\n",
            "  20000/  50000: 1.9295\n",
            "  30000/  50000: 2.1643\n",
            "  40000/  50000: 1.8935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-V8laMwxt6U",
        "outputId": "e10bf045-8f82-42ed-dce5-c2f11ba6445e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0637736320495605\n",
            "val 2.1294100284576416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBhbWc6gxy1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW6JNgCr9TM6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "id": "HuiTFulazIQB",
        "outputId": "43a2079e-6661-4665-f03a-b7dfcf742ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0, 16],\n",
              "        [ 0,  0,  0,  1, 21,  2, 18,  9],\n",
              "        [ 0,  0,  0,  0,  0, 19,  9,  7],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].out.shape"
      ],
      "metadata": {
        "id": "9TUEwOBJzrN8",
        "outputId": "d41fb207-df3e-40f1-d16c-e60dab886a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[1].out.shape"
      ],
      "metadata": {
        "id": "dgdTlqyjzyOQ",
        "outputId": "a2e8b090-2762-4ee0-8191-1ae34025fc16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[2].out.shape"
      ],
      "metadata": {
        "id": "QouNXmRbzzkG",
        "outputId": "eb9cdde7-0b47-4953-baeb-baeff8f0ed7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.randn((4,80)) @ torch.randn((80, 200)) + torch.randn((200))).shape"
      ],
      "metadata": {
        "id": "ddzxKaZT2dHi",
        "outputId": "721e8b11-2299-4b93-96be-2ebceb8eb2c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.randn((4, 5,80)) @ torch.randn((80, 200)) + torch.randn((200))).shape"
      ],
      "metadata": {
        "id": "j8ga4Ic627LJ",
        "outputId": "29b4469f-8d23-44a6-93cc-017a52f0a5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 5, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1, 2), (3, 4), (5, 6), (7, 8)"
      ],
      "metadata": {
        "id": "Dvux-o-Z3RjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.randn((4, 4, 20)) @ torch.randn((20, 200)) + torch.randn((200))).shape"
      ],
      "metadata": {
        "id": "YXyEM60b32cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc7deb3-d632-4c82-dcf2-cba3d23a56c4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.randn((4, 8, 10))\n",
        "e.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWOKXgmMbW6W",
        "outputId": "5d6f33f1-eb4c-48ac-9aae-6936939d51ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.view(e.shape[0], -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvsKj-R7bmGB",
        "outputId": "1f8a764e-42a2-4e46-a4c6-6be44148bae4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4npgPsmucP8S",
        "outputId": "8be5036f-f25e-4aee-b6ac-c5ee25ab73a3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.view(4, 4, 20).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvhqJl1wcCdW",
        "outputId": "f098d6b4-baf0-4d0b-bb85-c43e94e94a2d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdDwVvUp9TJR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fswEZ9hS9TCl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this Flatten to reflect consequitive flatten\n",
        "class Flatten:\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x.view(x.shape[0], -1)\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "nYmv6cG8a1dh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kto15AK9eDUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-goFZmrabHww"
      },
      "outputs": [],
      "source": [
        "# Near copy paste of the layers we have developed in Part 3\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Linear:\n",
        "\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class BatchNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      if x.ndim == 2:\n",
        "        dim = 0\n",
        "      elif x.ndim == 3:\n",
        "        dim = (0,1)\n",
        "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
        "      xvar = x.var(dim, keepdim=True) # batch variance\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Embedding:\n",
        "\n",
        "  def __init__(self, num_embeddings, embedding_dim):\n",
        "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "  def __call__(self, IX):\n",
        "    self.out = self.weight[IX]\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight]\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class FlattenConsecutive:\n",
        "\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "\n",
        "  def __call__(self, x):\n",
        "    B, T, C = x.shape\n",
        "    x = x.view(B, T//self.n, C*self.n)\n",
        "    if x.shape[1] == 1:\n",
        "      x = x.squeeze(1)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Sequential:\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    # get parameters of all layers and stretch them out into one list\n",
        "    return [p for layer in self.layers for p in layer.parameters()]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(8),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaQQk_H9eE9F",
        "outputId": "1cf7cae8-bb8a-420f-875b-a6fa6cb0a2b5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s4-E7a-ek_J",
        "outputId": "36323219-f043-4c5c-ea9d-38d14937286c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  1,  8, 25,  1, 14],\n",
              "        [ 0,  0,  0,  0,  4,  1, 14, 20],\n",
              "        [ 0,  0,  0,  0, 13,  5, 12,  9],\n",
              "        [ 0,  0,  0,  0, 16, 18,  5, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhQ3no6HewJg",
        "outputId": "6331796c-84cc-47ee-a530-38a8cfd2e528"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (4, 8, 10)\n",
            "FlattenConsecutive : (4, 80)\n",
            "Linear : (4, 200)\n",
            "BatchNorm1d : (4, 200)\n",
            "Tanh : (4, 200)\n",
            "Linear : (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this to work with FlattenConsecutive(2) and add more layers\n",
        "\n",
        "\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc_lyfBtfNs4",
        "outputId": "499fd6bb-dd85-44df-8b8f-78b7bc9b65b4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), Linear( 2 * n_embd, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear( 2 * n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutive(2), Linear( 2 * n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKh8AQ9_f0VM",
        "outputId": "2a30d4f9-b6fd-4d88-8c6b-ba55fc1ac585"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvDCdGhhgW_t",
        "outputId": "d804f5dd-573e-472c-8528-794a36a15c46"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0, 20,  5, 25,  1],\n",
              "        [ 0,  0,  0, 13,  9,  3, 11,  9],\n",
              "        [ 0, 11,  1, 18,  1, 12,  9, 14],\n",
              "        [ 0,  0,  0, 20, 25,  8,  5,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MLmYtICgeZI",
        "outputId": "321ebc6a-6df6-4293-daa1-4a97c0dc51b4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (4, 8, 10)\n",
            "FlattenConsecutive : (4, 4, 20)\n",
            "Linear : (4, 4, 200)\n",
            "BatchNorm1d : (4, 4, 200)\n",
            "Tanh : (4, 4, 200)\n",
            "FlattenConsecutive : (4, 2, 400)\n",
            "Linear : (4, 2, 200)\n",
            "BatchNorm1d : (4, 2, 200)\n",
            "Tanh : (4, 2, 200)\n",
            "FlattenConsecutive : (4, 400)\n",
            "Linear : (4, 200)\n",
            "BatchNorm1d : (4, 200)\n",
            "Tanh : (4, 200)\n",
            "Linear : (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "BZPsHiCdeW1_",
        "outputId": "92c05a7f-c57f-4862-8215-c66560547c3b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.4826\n",
            "  10000/ 200000: 2.5262\n",
            "  20000/ 200000: 2.2998\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-775ae06ecfef>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# update: simple SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "v01gpFOSbHwx"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42); # seed rng for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "vHMDMtvpbHwx",
        "outputId": "c8136cf6-f902-46cc-fc48-041e5e1328b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76579\n"
          ]
        }
      ],
      "source": [
        "# original network\n",
        "# n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "# n_hidden = 300 # the number of neurons in the hidden layer of the MLP\n",
        "# model = Sequential([\n",
        "#   Embedding(vocab_size, n_embd),\n",
        "#   FlattenConsecutive(8), Linear(n_embd * 8, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "#   Linear(n_hidden, vocab_size),\n",
        "# ])\n",
        "\n",
        "# hierarchical network\n",
        "n_embd = 24 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
        "model = Sequential([\n",
        "  Embedding(vocab_size, n_embd),\n",
        "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Sh9SEATabHwy",
        "outputId": "dd6f79f4-1010-4be2-b7cb-c11b790ec334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3167\n",
            "  10000/ 200000: 2.0576\n",
            "  20000/ 200000: 2.0723\n",
            "  30000/ 200000: 2.5134\n",
            "  40000/ 200000: 2.1476\n",
            "  50000/ 200000: 1.7836\n",
            "  60000/ 200000: 2.2592\n",
            "  70000/ 200000: 1.9331\n",
            "  80000/ 200000: 1.6875\n",
            "  90000/ 200000: 2.0395\n",
            " 100000/ 200000: 1.7736\n",
            " 110000/ 200000: 1.9569\n",
            " 120000/ 200000: 1.7465\n",
            " 130000/ 200000: 1.8126\n",
            " 140000/ 200000: 1.7406\n",
            " 150000/ 200000: 1.7466\n",
            " 160000/ 200000: 1.8805\n",
            " 170000/ 200000: 1.6266\n",
            " 180000/ 200000: 1.6476\n",
            " 190000/ 200000: 1.8555\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "XrOSTEFzbHwz",
        "outputId": "96fcae84-ecb3-40b3-b5bd-25a042c7069a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a6a3eb4dc90>]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkT0lEQVR4nO3deXzT9eE/8FeOJul93ydtgVKgLVCoKKeWwy8qgk5kTrBOnQJOrXPI/AlTt5Wpc2zKwLl5gVM2xVsLUm4oAi3lppTS0oPepUnPJE0+vz+SfNpIoU1pmx6v5+ORh+Rz9f0mQF6+T4kgCAKIiIiI+jGpvQtARERE1BkGFiIiIur3GFiIiIio32NgISIion6PgYWIiIj6PQYWIiIi6vcYWIiIiKjfY2AhIiKifk9u7wL0BKPRiMuXL8PV1RUSicTexSEiIqIuEAQB9fX1CAoKglR6/TaUQRFYLl++jNDQUHsXg4iIiLqhuLgYISEh171mUAQWV1dXAKYKu7m52bk0RERE1BUajQahoaHi9/j1DIrAYukGcnNzY2AhIiIaYLoynIODbomIiKjfY2AhIiKifo+BhYiIiPo9BhYiIiLq9xhYiIiIqN9jYCEiIqJ+j4GFiIiI+r1uBZb169cjIiICKpUKSUlJOHz48DWv3bp1KxITE+Hh4QFnZ2ckJCRg06ZNVtc0NDRgxYoVCAkJgaOjI2JjY7Fx48buFI2IiIgGIZsXjtuyZQtSU1OxceNGJCUlYd26dZgzZw5yc3Ph5+d31fVeXl544YUXEBMTA4VCgW+++QYpKSnw8/PDnDlzAACpqanYuXMnNm/ejIiICGzfvh3Lli1DUFAQ7rrrrhuvJREREQ1oEkEQBFtuSEpKwsSJE/HWW28BMG08GBoaiieffBLPP/98l54xfvx4zJs3D6+88goAYMyYMVi0aBFefPFF8ZoJEybg9ttvxx/+8IdOn6fRaODu7g61Ws2VbomIiAYIW76/beoS0ul0yMrKQnJyctsDpFIkJycjMzOz0/sFQUBGRgZyc3Mxbdo08fjNN9+Mr776CqWlpRAEAbt27cL58+cxe/bsDp+j1Wqh0WisXkRERDR42dQlVF1dDYPBAH9/f6vj/v7+OHfu3DXvU6vVCA4OhlarhUwmwz/+8Q/MmjVLPP/mm2/iscceQ0hICORyOaRSKd555x2rUNNeWloaXnrpJVuKTkRERANYn2x+6OrqipycHDQ0NCAjIwOpqamIjIzEjBkzAJgCy6FDh/DVV18hPDwce/fuxfLlyxEUFGTVmmOxatUqpKamiu8tuz32tBa9AX/ZnotmvQFr7hwNBxknVREREdmDTYHFx8cHMpkMFRUVVscrKioQEBBwzfukUimio6MBAAkJCTh79izS0tIwY8YMNDc343e/+x0+//xzzJs3DwAQFxeHnJwcvP766x0GFqVSCaVSaUvRu0UiAd7ZVwAA+O3cGAYWIiIiO7HpG1ihUGDChAnIyMgQjxmNRmRkZGDy5Mldfo7RaIRWqwUA6PV66PV6SKXWRZHJZDAajbYUr8cpZFJIzTtet+gMdi0LERHRUGZzl1BqaiqWLl2KxMRETJo0CevWrUNjYyNSUlIAAEuWLEFwcDDS0tIAmMabJCYmIioqClqtFt999x02bdqEDRs2AADc3Nwwffp0PPfcc3B0dER4eDj27NmDDz/8EG+88UYPVtV2EokEKgcZmnQGNOsZWIiIiOzF5sCyaNEiVFVVYfXq1SgvL0dCQgLS09PFgbhFRUVWrSWNjY1YtmwZSkpK4OjoiJiYGGzevBmLFi0Sr/nkk0+watUqPPDAA6itrUV4eDj++Mc/4vHHH++BKt4YR3NgadHbt7WHiIhoKLN5HZb+qDfXYbll7U6U1jXji+W3ICHUo0efTURENJT12josQ5HKwfRb1MwxLERERHbDwNIJR4UMANDSysBCRERkLwwsnXB0MAcWtrAQERHZDQNLJ1TmwMJZQkRERPbDwNIJS2DhLCEiIiL7YWDphCNbWIiIiOyOgaUTlllCLQwsREREdsPA0glx0C0DCxERkd0wsHRCZZ7WzHVYiIiI7IeBpRMqOcewEBER2RsDSyfEheM4S4iIiMhuGFg6wTEsRERE9sfA0glxLyEGFiIiIrthYOmEii0sREREdsfA0gkuzU9ERGR/DCydcOTS/ERERHbHwNKJtllCbGEhIiKyFwaWTojrsHDhOCIiIrthYOmEo8K8l1ArAwsREZG9MLB0Qhx0yxYWIiIiu2Fg6YQlsGhbjTAaBTuXhoiIaGhiYOmEZZYQYAotRERE1PcYWDqhahdYuBYLERGRfTCwdEImlUAh4/L8RERE9sTA0gWW/YS4FgsREZF9MLB0gWXxOM4UIiIisg8Gli7gBohERET2xcDSBdxPiIiIyL4YWLqAOzYTERHZFwNLF1gG3TKwEBER2QcDSxc4cgwLERGRXTGwdAEH3RIREdkXA0sXOHIDRCIiIrtiYOkClYKzhIiIiOyJgaULVHLOEiIiIrInBpYucFRwaX4iIiJ7YmDpAs4SIiIisi8Gli7gwnFERET2xcDSBSrOEiIiIrIrBpYuELuEWjlLiIiIyB4YWLpAXDiOLSxERER20a3Asn79ekREREClUiEpKQmHDx++5rVbt25FYmIiPDw84OzsjISEBGzatOmq686ePYu77roL7u7ucHZ2xsSJE1FUVNSd4vU4yywhjmEhIiKyD5sDy5YtW5Camoo1a9YgOzsb8fHxmDNnDiorKzu83svLCy+88AIyMzNx4sQJpKSkICUlBdu2bROvyc/Px5QpUxATE4Pdu3fjxIkTePHFF6FSqbpfsx7EpfmJiIjsSyIIgmDLDUlJSZg4cSLeeustAIDRaERoaCiefPJJPP/88116xvjx4zFv3jy88sorAID7778fDg4OHba8dIVGo4G7uzvUajXc3Ny69YzryS66goX/OIgQT0fsX3lrjz+fiIhoKLLl+9umFhadToesrCwkJye3PUAqRXJyMjIzMzu9XxAEZGRkIDc3F9OmTQNgCjzffvstRowYgTlz5sDPzw9JSUn44osvrvkcrVYLjUZj9epNXIeFiIjIvmwKLNXV1TAYDPD397c67u/vj/Ly8mvep1ar4eLiAoVCgXnz5uHNN9/ErFmzAACVlZVoaGjA2rVrMXfuXGzfvh0LFizAwoULsWfPng6fl5aWBnd3d/EVGhpqSzVs1hZYOEuIiIjIHuR98UNcXV2Rk5ODhoYGZGRkIDU1FZGRkZgxYwaMRlMImD9/Pp555hkAQEJCAg4ePIiNGzdi+vTpVz1v1apVSE1NFd9rNJpeDS3tF44TBAESiaTXfhYRERFdzabA4uPjA5lMhoqKCqvjFRUVCAgIuOZ9UqkU0dHRAExh5OzZs0hLS8OMGTPg4+MDuVyO2NhYq3tGjRqF/fv3d/g8pVIJpVJpS9FviKWFxWAUoDcIUMgZWIiIiPqSTV1CCoUCEyZMQEZGhnjMaDQiIyMDkydP7vJzjEYjtFqt+MyJEyciNzfX6prz588jPDzcluL1GqVD229TSyvHsRAREfU1m7uEUlNTsXTpUiQmJmLSpElYt24dGhsbkZKSAgBYsmQJgoODkZaWBsA03iQxMRFRUVHQarX47rvvsGnTJmzYsEF85nPPPYdFixZh2rRpmDlzJtLT0/H1119j9+7dPVPLG6SUSyGRAIJgWjzOTeVg7yIRERENKTYHlkWLFqGqqgqrV69GeXk5EhISkJ6eLg7ELSoqglTa1iLR2NiIZcuWoaSkBI6OjoiJicHmzZuxaNEi8ZoFCxZg48aNSEtLw69//WuMHDkSn332GaZMmdIDVbxxEokEjg4yNOkMXDyOiIjIDmxeh6U/6u11WABg/Cs/oLZRh21PT8PIANde+RlERERDSa+twzKUObabKURERER9i4Gli1TmgbfN3ACRiIiozzGwdJG4nxBnCREREfU5BpYuclKYAkujttXOJSEiIhp6GFi6yM/NtHN0ubrFziUhIiIaehhYuijI3RRYyhhYiIiI+hwDSxcFujsCAMrUzXYuCRER0dDDwNJFQR6mwFJaxxYWIiKivsbA0kVBHuYuoTq2sBAREfU1BpYusrSwVDVooWs12rk0REREQwsDSxd5OyugkEshCECFht1CREREfYmBpYskEgkCzTOFLrNbiIiIqE8xsNggyDxT6DJnChEREfUpBhYbBHpYWljYJURERNSXGFhsEMS1WIiIiOyCgcUGlplCbGEhIiLqWwwsNmjrEmILCxERUV9iYLFBsIelS4gtLERERH2JgcUGlmnN6mY9GrWtdi4NERHR0MHAYgNXlQNclXIAHHhLRETUlxhYbMRNEImIiPoeA4uNArkJIhERUZ9jYLGROLWZA2+JiIj6DAOLjUI8TYHlUk2jnUtCREQ0dDCw2CgmwBUAcLZMY+eSEBERDR0MLDaKDXQHAORXNaJFb7BzaYiIiIYGBhYb+bsp4enkAINRQF5Fg72LQ0RENCQwsNhIIpEgNsgNAHCmTG3n0hAREQ0NDCzdMCrAFFjOltXbuSRERERDAwNLN4gtLJc58JaIiKgvMLB0gyWwnC3TQBAEO5eGiIho8GNg6YYoXxcoZFLUa1tRcoUr3hIREfU2BpZucJBJMdzfBQBwhuuxEBER9ToGlm4aFchxLERERH2FgaWbYgPbxrEQERFR72Jg6abR5oG3Ry9d4Yq3REREvYyBpZsmhHsiyF2F2kYdvj5+2d7FISIiGtQYWLpJLpPiwckRAID3DhRyejMREVEvYmC5AYsnhULlIMWZMg1+LKi1d3GIiIgGLQaWG+DhpMDC8SEAgPcOFNi5NERERINXtwLL+vXrERERAZVKhaSkJBw+fPia127duhWJiYnw8PCAs7MzEhISsGnTpmte//jjj0MikWDdunXdKVqfS7k5AgDww5kKVDdo7VsYIiKiQcrmwLJlyxakpqZizZo1yM7ORnx8PObMmYPKysoOr/fy8sILL7yAzMxMnDhxAikpKUhJScG2bduuuvbzzz/HoUOHEBQUZHtN7GS4vytG+LvAKADHi+vsXRwiIqJByebA8sYbb+DRRx9FSkoKYmNjsXHjRjg5OeHdd9/t8PoZM2ZgwYIFGDVqFKKiovDUU08hLi4O+/fvt7qutLQUTz75JD766CM4ODh0rzZ2MibYHQBwslRt55IQERENTjYFFp1Oh6ysLCQnJ7c9QCpFcnIyMjMzO71fEARkZGQgNzcX06ZNE48bjUY8+OCDeO655zB69OhOn6PVaqHRaKxe9hRnCSwlDCxERES9wabAUl1dDYPBAH9/f6vj/v7+KC8vv+Z9arUaLi4uUCgUmDdvHt58803MmjVLPP/nP/8Zcrkcv/71r7tUjrS0NLi7u4uv0NBQW6rR48aGeAAATpSqOb2ZiIioF8j74oe4uroiJycHDQ0NyMjIQGpqKiIjIzFjxgxkZWXhb3/7G7KzsyGRSLr0vFWrViE1NVV8r9Fo7BpaYgPdIJUAVfVaVGi0CHBX2a0sREREg5FNgcXHxwcymQwVFRVWxysqKhAQEHDN+6RSKaKjowEACQkJOHv2LNLS0jBjxgzs27cPlZWVCAsLE683GAx49tlnsW7dOhQWFl71PKVSCaVSaUvRe5WjQoYR/q44V16Pk6VqBhYiIqIeZlOXkEKhwIQJE5CRkSEeMxqNyMjIwOTJk7v8HKPRCK3WNAX4wQcfxIkTJ5CTkyO+goKC8Nxzz3U4k6i/GiuOY6mzb0GIiIgGIZu7hFJTU7F06VIkJiZi0qRJWLduHRobG5GSkgIAWLJkCYKDg5GWlgbANN4kMTERUVFR0Gq1+O6777Bp0yZs2LABAODt7Q1vb2+rn+Hg4ICAgACMHDnyRuvXZ8aGuON/WSU4wZlCREREPc7mwLJo0SJUVVVh9erVKC8vR0JCAtLT08WBuEVFRZBK2xpuGhsbsWzZMpSUlMDR0RExMTHYvHkzFi1a1HO16AfGtpspJAhCl8fjEBERUeckwiCY1qLRaODu7g61Wg03Nze7lKFFb8CYNdvQahRw8PlbEeThaJdyEBERDRS2fH9zL6EeonKQYbi/KwDgBNdjISIi6lEMLD1oVKApsFyorLdzSYiIiAYXBpYeNMzbGQBQUN1k55IQERENLgwsPWiYryWwNNi5JERERIMLA0sPijC3sBTWsIWFiIioJzGw9KBhPqbAUtuog7pJb+fSEBERDR4MLD3IWSmHn6tpy4CCmkY7l4aIiGjwYGDpYZZWFo5jISIi6jkMLD0s0pczhYiIiHoaA0sPixCnNrNLiIiIqKcwsPQwS5dQIQMLERFRj2Fg6WFtY1gaMQi2aSIiIuoXGFh6WJi3EyQSoEHbiuoGnb2LQ0RENCgwsPQwpVyGYPNOzRzHQkRE1DMYWHoBx7EQERH1LAaWXmAJLLkV3LWZiIioJzCw9ILRQW4AgHcPFODV9HPQG4x2LhEREdHAxsDSCxaOD8F9iSEQBOAfu/Px64+P2btIREREAxoDSy9wkEnx6r3x+PvicQCAbafL0aI32LlUREREAxcDSy+6My4Qnk4OMApAXgX3FiIiIuouBpZeJJFIMDLAFQBwrlxj59IQERENXAwsvSwmwDQA91w5ZwwRERF1FwNLL4sxt7DkMrAQERF1GwNLL4sJtLSwsEuIiIiouxhYetkIfxdIJEB1gw5V9Vp7F4eIiGhAYmDpZU4KOcK9nACwW4iIiKi7GFj6AGcKERER3RgGlj7AmUJEREQ3hoGlD3CmEBER0Y1hYOkDlplC5yvqYTAKdi4NERHRwMPA0gfCvJzg6CCDttWIv2XkwcjQQkREZBMGlj4gk0rw2LRIAMDfM/LwyIdH0aRrtXOpiIiIBg4Glj7yzKwRePXeOCjkUuw8V4l39xfYu0hEREQDBgNLH7ovMRRr7owFAKSfLrdzaYiIiAYOBpY+Nmd0AKQS4FSpBqV1zfYuDhER0YDAwNLHfFyUSAz3AgD8wFYWIiKiLmFgsYPZo/0BANtOV9i5JERERAMDA4sdzI4NAAAcLqzFlUadnUtDRETU/zGw2EGYtxNiAlxhMArYea7S3sUhIiLq9xhY7GT2aFMrS9r357A1u4SLyREREV0HA4ud/OKmMAzzcUZ1gxap/z2OxzdnQRAYWoiIiDrSrcCyfv16REREQKVSISkpCYcPH77mtVu3bkViYiI8PDzg7OyMhIQEbNq0STyv1+uxcuVKjB07Fs7OzggKCsKSJUtw+fLl7hRtwPBzVSH96alYOTcGCpkU289U4Fhxnb2LRURE1C/ZHFi2bNmC1NRUrFmzBtnZ2YiPj8ecOXNQWdnxWAwvLy+88MILyMzMxIkTJ5CSkoKUlBRs27YNANDU1ITs7Gy8+OKLyM7OxtatW5Gbm4u77rrrxmo2ACjlMjwxIwp3xAcCAD45XGTnEhEREfVPEsHGfoikpCRMnDgRb731FgDAaDQiNDQUTz75JJ5//vkuPWP8+PGYN28eXnnllQ7PHzlyBJMmTcKlS5cQFhbW6fM0Gg3c3d2hVqvh5ubW9cr0E0cKa/GzjZlwdJDh8Au3wVXlYO8iERER9Tpbvr9tamHR6XTIyspCcnJy2wOkUiQnJyMzM7PT+wVBQEZGBnJzczFt2rRrXqdWqyGRSODh4dHhea1WC41GY/UayBLDPRHt54JmvQFf5lh3hZXWNUPbarBTyYiIiPoHmwJLdXU1DAYD/P39rY77+/ujvPzaq7aq1Wq4uLhAoVBg3rx5ePPNNzFr1qwOr21pacHKlSuxePHia6attLQ0uLu7i6/Q0FBbqtHvSCQS3D/RVIdPjpi6hQRBwLod53HL2p1I3XLcnsUjIiKyO3lf/BBXV1fk5OSgoaEBGRkZSE1NRWRkJGbMmGF1nV6vx3333QdBELBhw4ZrPm/VqlVITU0V32s0mgEfWhaOD8Gr6bk4VarBgn8cgLezAjvOmsYF7T1fBaNRgFQqsXMpiYiI7MOmwOLj4wOZTIaKCusl5SsqKhAQEHDN+6RSKaKjowEACQkJOHv2LNLS0qwCiyWsXLp0CTt37rxuX5ZSqYRSqbSl6P2el7MCz84egde25eJYUR0AQC6VQCIB6rWtyK9qwHB/V/sWkoiIyE5s6hJSKBSYMGECMjIyxGNGoxEZGRmYPHlyl59jNBqh1WrF95awkpeXhx07dsDb29uWYg0av5oehYOrbsVzc0Zi+ghffPjLSRgX5gkAnPJMRERDms1dQqmpqVi6dCkSExMxadIkrFu3Do2NjUhJSQEALFmyBMHBwUhLSwNgGm+SmJiIqKgoaLVafPfdd9i0aZPY5aPX63HvvfciOzsb33zzDQwGgzgexsvLCwqFoqfqOiD4uaqwfGY0ls80vd+TW4XDBbXIKa7DfYmhqG7Q4lxZPaYM97FvQYmIiPqQzYFl0aJFqKqqwurVq1FeXo6EhASkp6eLA3GLiooglbY13DQ2NmLZsmUoKSmBo6MjYmJisHnzZixatAgAUFpaiq+++gqAqbuovV27dl01zmWoSQj1AADkmLuJHvvwKLKL6rDlsZuQFDk0W6KIiGjosXkdlv5ooK/Dcj2X65px89qdkEkl2PLYTbh3o2n6+Av/NwqPTou0c+mIiIi6r9fWYaG+F+iugp+rEgajgDVfnRaPF9Q02rFUREREfYuBpZ+TSCRit9Dpy20L5BVUMbAQEdHQwcAyACSEeYi/VshMH1khW1iIiGgIYWAZACwtLACwZHI4AKBM3YJmHZfsJyKioYGBZQCIC/GAk0IGhUyKR6dFwsPJtDkiW1mIiGio6JOl+enGuCjl+OSxmyAIgL+bChHezshpqkNBdSNGBQ6uWVFEREQdYQvLABEX4oF4c9dQpI8zAKCgmi0sREQ0NDCwDEARDCxERDTEMLAMQMPMgaWQgYWIiIYIBpYBaFi7FhZ1kx6PfHAU7+y9aOdSERER9R4GlgHI0iVU06jDS1+fxo6zFfjT92dxskRt55IRERH1DgaWAchFKYevqxIAsPVYKQBAEIDVX52C0Tjgt4YiIiK6CgPLAGXpFgKAm6O84ayQ4VhRHT7NLhGPl9Y146WvT+NcuaajRxAREQ0YDCwD1DBvU2BRyKVYuzAOTyePAAD86buzOFxQi8t1zbj/n5l470Ah3th+3p5FJSIiumEMLAPU1BE+AICnbhuOMG8nPHRLBMYEu6GuSY/7/5mJ+esPoLi2GQBwvKTOjiUlIiK6cQwsA9QdcUE4vno2ls+MBgA4yKTY8thkLBwfDKMAVNVrEeLpCKkEqNBoUaFpAQB8ffwy/px+DuomvT2LT0REZBMGlgHM3bynkIWzUo437kvA3+5PwD3jQ/DJYzch2s8FAHCiRI0WvQG//fQENuzOx6y/7sGOMxX2KDYREZHNGFgGofkJwfjLffEI8XRCXIgHAOBESR2OFNaiWW/a4bmyXotHPjyK7afL7VhSIiKirmFgGeTiQ9wBmFpY9uRWAQDuig/CgnHBAIBNhy7ZrWxERERdxd2aB7mx7VpYSutMg3DnjA7AmGA3fH6sFAcuVKOyvgV+rio7lpKIiOj62MIyyI0KdIWDTIIrTXpcqGyAVAJMifZBuLczxod5wCgAXx8vs3cxiYiIrouBZZBTymWICXAT348L8xQH61q6hb4wr5ZLRETUXzGwDAFjzeNYAGD6CF/x1/PigiCXSnCyVI0LlQ32KBoREVGXMLAMAfHXCCxezgrx/Zc5bGUhIqL+i4FlCEiM8IJEAvi7KTE22N3q3B3xgQCAveer7FE0IiKiLuEsoSEgytcFm3+ZBD9XJaRSidW5CWFeAICzZfXQtRqhkEvRajCiUWu4amE6IiIie2ELyxBxS7QPhvu7XnU81MsRnk4O0BmM4q7Oj354FBP+8AP+sfsCDEahr4tKRER0FQaWIU4ikYir4R4vrkNdkw57zleh1Sjg1fRc/PydQ9x3iIiI7I6BhcRBuTnFauy/UA2jAHg7K+CkkOHHglr8c1++nUtIRERDHcewEOJDPQCYVsOVmSPs3eOCERPgiuc+PYGD+TX2KxwREREYWAgQu4QuVDXgSpMOADBthC8ifZwBACdL1GjStcJJwT8uRERkH+wSIvi6KhHkroIgANUNOijlUiQN80KolxOCPRzRahSQfanO3sUkIqIhjIGFALR1CwHApGFeUDnIxF8DwOGCGgiCgPW7LuAfuy/Yo4hERDSEMbAQgLZuIcB6NVxLYDlUUIsDF2rw2rZcvJqeix8vclwLERH1HQYWAgDEh7atgDutXWBJMgeWnOI6vLbtnHj8rV2mVpbsoit48N8/IuvSlT4qKRERDUUcRUkAgHGhnojwdoKvqxLD/VzE48N8nOHjokR1gxbHS9RQyqUwGAXsy6vG18cvY81Xp1HbqMPlumZse3oa5DIpzpZp0Kw3YHyYpx1rREREgwkDCwEAHBUy7H5uJgRBgETStny/RCJB0jAvfHuyDACwZHI46pr0+F9WCZ78+Jh4XX5VI7YcLUZMgBsW//MQAODgqlvh46Ls24oQEdGgxC4hstI+rFgkRZq6hRwdZPjV9CgsmxkNy5ZEvq5KPDEjCgDw1x/O41ebsqAzGKEzGJHNbiIiIuohDCzUqfnxwbg1xg+v3D0GPi5KDPNxxsO3DIOfqxLvLEnEM8kjEOHthOoGHaobtOJ9OcV19is0ERENKhJBEAb87nYajQbu7u5Qq9Vwc3Ozd3GGpPRTZXh8czZ8XBRYNDEU63fl45Zob3z0yE32LhoREfVTtnx/cwwL9Yi5YwLxwcOTEOnjjPqWVqzflY8TxWoYjQKkUgnqmnRwd3TosMvpp/blVcFN5WC1NgwREQ1t3eoSWr9+PSIiIqBSqZCUlITDhw9f89qtW7ciMTERHh4ecHZ2RkJCAjZt2mR1jSAIWL16NQIDA+Ho6Ijk5GTk5eV1p2hkR9NH+CLUywkj/F3g6CBDvbYV+VUN+P5kGRJe/gF/z+h8wbkLlQ1Y8u5h/OJfP6JZZ+iDUhMR0UBgc2DZsmULUlNTsWbNGmRnZyM+Ph5z5sxBZWVlh9d7eXnhhRdeQGZmJk6cOIGUlBSkpKRg27Zt4jWvvvoq/v73v2Pjxo348ccf4ezsjDlz5qClpaX7NSO7kcukGGveAfpYcR3e3GkKKv/adxGN2lara6806vBlTilaDUYAwNfHL0MQgHptK/ac7/jPFBERDT02B5Y33ngDjz76KFJSUhAbG4uNGzfCyckJ7777bofXz5gxAwsWLMCoUaMQFRWFp556CnFxcdi/fz8AU+vKunXr8P/+3//D/PnzERcXhw8//BCXL1/GF198cUOVI/tJMHfnvH+gEGfKNABMIWRrdol4jSAIWPZRNp76JAfrd+VDEAR8c+KyeP67k+V9WmYiIuq/bAosOp0OWVlZSE5ObnuAVIrk5GRkZmZ2er8gCMjIyEBubi6mTZsGACgoKEB5ebnVM93d3ZGUlHTNZ2q1Wmg0GqsX9S+WwGIJKz4uCgDA+wcLYTSaxnnvyq1EpnmJ/3cPFCDr0hXkVzWKz9h5rhItenYLERGRjYGluroaBoMB/v7+Vsf9/f1RXn7t/xtWq9VwcXGBQqHAvHnz8Oabb2LWrFkAIN5nyzPT0tLg7u4uvkJDQ22pBvWBhJ8MmN3wiwlwUcqRX9WI/ReqYTAKWPu9aal/iQRQN+vFheiSR/kj0F2FBm0r9udV93XRiYioH+qTdVhcXV2Rk5ODI0eO4I9//CNSU1Oxe/fubj9v1apVUKvV4qu4uLjnCks9ItBdBT9X0yq3kyK8MDHCC/dOCAEArP7yFJ7ZkoPzFQ3wcHLA6jtiAQBlatOYpTvjAzFndAAA4LtTZXYoPRER9Tc2BRYfHx/IZDJUVFRYHa+oqEBAQMC1f4hUiujoaCQkJODZZ5/Fvffei7S0NAAQ77PlmUqlEm5ublYv6l8kEgluG+UHAPjV9EgAQMotEXBTyVFY04SvjpvGqqyYGY0HbwpHqJcjAEApl+K2Uf74v7GBAIAdZyqgazVaPdtoFPD0J8fw20+PYxAsI0RERF1gU2BRKBSYMGECMjIyxGNGoxEZGRmYPHlyl59jNBqh1ZpWRB02bBgCAgKsnqnRaPDjjz/a9Ezqf9bcORq7fzMDt40ydfeFeztj2zPT8Ie7x2De2EDcMz4ED04Oh1wmxdO3jQAAzIsLhItSjgnhnvB1VULT0oodZ63DbG5FPb7IuYz/Hi0RW2WIiGhws3nhuNTUVCxduhSJiYmYNGkS1q1bh8bGRqSkpAAAlixZguDgYLEFJS0tDYmJiYiKioJWq8V3332HTZs2YcOGDQBM/yf+9NNP4w9/+AOGDx+OYcOG4cUXX0RQUBDuvvvunqsp9TmVgwwRPs5WxwLdHfGLm8Lxi5vCrY7fMyEEMYGuGGa+XiaVYFFiKN7adQHv7i8QW1wA4Ehhrfjrs2UaBHk49mItiIioP7A5sCxatAhVVVVYvXo1ysvLkZCQgPT0dHHQbFFREaTStoabxsZGLFu2DCUlJXB0dERMTAw2b96MRYsWidf89re/RWNjIx577DHU1dVhypQpSE9Ph0ql6oEq0kAxOsjd6v2SyeF4e28+jl66guPFdeLKt4cLrAOLpQWHiIgGL+4lRP1a6pYcbD1WivkJQfjb/eMgCAJuSstAhcbUpThvbCDWPzBevL5ZZ8Car05h6nBf3BkfZK9iExFRF9jy/c3dmqlfe3jKMADAtyfKUK5uQcmVZjGsAKYWlvY+P1aK/x4tEadMExHR4MDAQv3amGB3TBrmhVajgI178sXuoHBvJwBAQU0jmnRty/1/b54GXVrXjPoW/TWfe6mmEVcadb1YciIi6kkMLNTvPXXbcADA5kOX8GmWaWn/uaMD4OOihCAAueX1AAB1kx6Z+TXifXmVDR0+r7SuGbP/uhcPf3Ckl0tOREQ9hYGF+r1bon1wa4wfWo2CuJR/YoQXYoNM/Z2W5f9/OFuBVmPbkKzz5iDzUzlFddC2GnGsqA51TWxlISIaCBhYaED43f/FQCaViO8Twz0xKtAVQNs4lnRzd5DKwfTH+nxFxy0s+VVtx0+UqHulvERE1LMYWGhAiPZzxc8nhQEARvi7wNNZgdhAUwvL2bJ6NGhbsde879ADSaY1Xs5XdNzCYh1Y6nqx1ERE1FNsXoeFyF5+M2ckjIKAuWNMWzaMMgeWc2UabNydD12rEZE+zrgjLhD/3l+A3GsElovtdoQ+zhYWIqIBgYGFBgx3Rwf8ccFY8X2kjzMUcikadQa8tesCANOKuSP8TV1FVfVa1Dbq4OWsEO8RBIEtLEREAxC7hGjAksukSDCvfuvrqsTL80fj8elRcFbKxc0Uf9otVK5pQZPOAJlUAplUggqNFuWd7Ed0uKAWmw5d4kaLRER2xBYWGtDeuC8ep0rVmD7CD44KmXh8pL8rimubcb6iHjdFeovH8ytN3UHh3k5QyKQ4V16P4yV1CHC/9m7jqf/NQcmVZng7K6z2NCIior7DFhYa0EI8nTB3TKBVWAEgdgvl/mRqs6U7KNLHBfEhHgBM3UJGo4AKzdUtLQ3aVpRcaQYAvHegoKeLT0REXcTAQoOSJbD8tEvoojmwRPk5Iy7UtNni/rxq/OztTCT9KQO7zlV2eD0AHCm8glOlpkG6P+0euljVgO9PlrHbiIiol7BLiAYlS2A5VarBso+yoJBJsfrO0cg3zxCK8nURp0W3nyn0/akyzIzxE9+3H6ALAO8dKERSpBfWfn8OkyK88PLdo3GqVI0V/zmGJp0B76VMxMyRfugqo3mhO2m7NWaIiOhqDCw0KEX5OUPlIEWz3oDvTpYDAJRymRhAonxdMDLAFSoHKVr0Rvi4KFDdoMPBdkv7A21jXsYEu+FUqQafZZfgs2zT9gDpp8uRebEG9S16WBbY/fr45S4Hlsr6Fsxdtw+TIryw8cEJPVFtIqJBi11CNCgp5TK8syQRTycPxzPJIwAA/80qRpl5RlCUrzMcZFKsXRiH5TOj8P1T0yCXSlBypRnFtU3icywBZ+G4EMSbZyTJpBI8MSMKsYFuUDebwspNkV4AgB/OVEDXauxSGbefrkBtow7pp8txua65p6pORDQosYWFBq2pw30xdbgvAOBCVQO+Pn4ZAODjooCHk2ltlrvHBYvXJ4R64OilK8jMr0Gol2k3aHGQrq8z1i4ci3f2XcTPJ4UhMcILzySPwOZDl+CkkOFniaGYnJaBynotDuRXd6mVZb95ZV4A2H66HA/dMqxnKk5ENAixhYWGhJVzR0IpN/1xj/R16fCayVGm6c8H801BotVgRGG1qbUlytcFowLd8MZ9CUiMMLWmKORSPDxlGO6fFAaZVCKuwPv9yTLoDUb892gx8q6x2q7BKIg/BzB1LxER0bUxsNCQEOLphF9NiwQAjDN37fxUW2CpgSAIKL7SDJ3BCKVcimAPx05/xu1jTGu0bD9TgYffP4LffnoCqf893uG1J0rqoGlpFTdqPFxQi5oGra3VIiIaMtglREPGM7NG4OZoH8SFuHd4fnyYJxRyKSrrtbhY3YgC84yiSF+XLs3imTTMC97OCtQ06rDP3N1ztkwDbasBSrn1OjGW7qAZI/xQWteMk6Vq/HCmAvebN3gkIiJrbGGhIUMikeCmSG84KTrO6SoHGRLDPQGYWlnaZhQ5d+n5MqkEt481dQv5uynhopSj1Sggr6Lhqmv3XTAFlinDfcSupI+PFGPV1hNY/M9DuFTTeNU9RERDGQMLUTuTzcv4f5pVgvMVbVOguyp11kj8v3mj8NWKKRgTbFrn5UyZBoBpsbn6Fj0ata04VnQFADB1uA/mjDYFluPFdfj4cDEyL9bglW/O9lidiIgGAwYWonbumRACV6Ucx4vr8GVOKQAgyq/rgcXLWYFHpkbC302F2EBT19NZc2B5+ZszGPv77Uj6Uwb0BgGhXo4I93ZGtJ8LZsf6w9tZgYXjgiGVADvOViCnuK7H60dENFAxsBC1E+ThiDV3jQYAtJpXg+tql9BPxQaZW1gua6A3GPFplmnBuQZtKwAgeZS/eO0/lyQi68VZeGNRAhaMCwEA/GV7rtXzBEEQV8YlIhpqGFiIfuKe8cGYO7pt9+ZIn663sLQ3KtC0PcCZMg2OFl5BfUsrvJwV+GrFLXhnSSJ+M3tkh/c9nTwcDjIJ9uVV49BF08q7giDglx8cxaQ/7UCZmovMEdHQw8BC9BMSiQR/WjgWY4LdsGBc8FU7QXfVcD9XOMgkqG9pxUc/XgIATB/hi7gQD8yK9YezsuPBv6FeTlg0MRQAsPb7cxAEAQfza7DzXCWqG3R4/2Bht8pDRDSQMbAQdcDLWYFvnpyKvy5K6PYzFHIpov1MrSzfniwDAKuNFa/n17cOh5NChpziOnx7sgxv7swTz31yuBhNula0Goz4MqeUy/oT0ZDAwELUiyzdQoIASCXAtOE+XbrPz02FX02LAgD8vy9O4dDFWjjIJAh0V0HdrMdn2aV4futJPPVJDh7bdBSC0PHYlotVDXjkg6P4zDx+pj1BEJBf1QADx8UQ0QDAwELUi2ID3cRfTwj3FPcw6opHpw2Dv5sSdU16AMC9E0Lw6FTTar1/+OaMOIj3VKkGu89XXXX//rxq3L3+AHacrcBfd5y3OldVr8VD7x3BbX/Zg/W7LthcLyKivsbAQtSLLDOFAGBGFzZEbM9JIcez5oG5MqkET0yPxs8SQ+CilENr3hHastbLWzsvWLWy7MurwtL3DkPTYpqRVHKlGVcadQCArEtXcPvf9mKPOeTsyq3sZu2IiPoOAwtRL2rfwnJrF8evtHfP+BA8kzwCr94ThzBvJ7iqHPDQzREAgF/fNhz/XjoRCrkUWZeu4NDFWvG+T7NKYDAKmBXrj1Av0z5IJ0vVAICXvj6N6gYdIrxNO1KfLtWgRW/obhWJiPoEAwtRL/JwUuD/zRuFp5OHIybA1eb7ZVIJnkoejnsmhIjHUmeNQOaqW5E6awT83VS4L9F0rn3Xzrky0y7RiyeFIj7EA4ApsKib9WJw+eSxyfBxUUBnMOL0ZXWXy7Q/rxofZhbaXBciohvBwELUyx6ZGomnk0dAIul8A8WukEolCHRv2z3aMjh3/4VqXGnUQdtqEPdBiglwEzd7PFWqxpGCWggCEOnjjAB3FcaFmfZOyrp0pUs/W9tqwBObs7D6y9M4zpV4iagPMbAQDXChXk6INK/Ge6z4CvIqGtBqFODu6IBAdxXGBJsCy4kStbgQXZJ5z6QJ5s0esy/VWT1za3YJ7tuYiRMl1scP5teg3rxSr6WlhoioLzCwEA0C48Pagodl76JRga6QSCRiYCmta8b2MxUAgJsivQC0BZasoivioN1TpWqs/OwEDhfWIuW9Iyiobts5evvpcvHXpy9rrlkeXasRdU26nqoeEREDC9FgIAaWois4ax6/Mso84NdN5YBhPqYWmKLaJgDATeYWlrHB7pBLJaiq16LkSjNa9AY8syUHeoMAuVSCmkYdlrz7IyrrW2AwCvjBHHiAtl2o22vQtuLtPfm45c87kfiHHdi4J5/7HxFRj2BgIRoExoV5AACOF9fhlHkA7ah2M5QsrSyAafyKv5sKAKBykGG0+dzhglq89PVp5FU2wMdFie+emoowLycU1zbj8U1Z+LGgBtUNOsilprE458o0aDUYxefWNGgx5697kfb9OVTVa9FqFLD2+3NY+t5htrYQ0Q1jYCEaBEb4u8JFKUejzoCjhabpze2nVI8Nbvu1ZfyKxQRz68yqrSfx8eFiAMBr98ZhhL8rPnh4ElxVcmQX1WHFf44BAObFBcJJIYO21YjCmrbuot9/fQaldc0Iclfh1Xvj8KcFY6FykGJfXjVWfnaidypOREMGAwvRICCTShAfamopMQqm99F+bbtMjw32EH9tGb9iMT7cdE5nMMLd0QHrFiWIex4N83HGX+9LAADUmheeu31MgDhF2zKOZdvpcnx9/DJkUgnefjAR9yWG4udJYfjvryZDLpVg2+kKpJ8q67DsRTVNWP5RNlZ+egL/2H0Bhe3GzBARWTCwEA0SlnEsgKnbR+XQtsv0mGA3OMgkkEraxq9YTB/hi/hQD9wVH4QfUqfh7nHBVueTY/2xfKZp6rRSLsW0Eb7iCr5nyjRQN+nx/744BQB4bFokxoa0dT/FhXjgiRmme1/88jTUzfqryr1xbz6+PVmGLUeL8Wp6Lh798OiN/DZ0W7POgK+PX0aTrtUuP5+Irq/j/e2JaMBpH1jaj18BAFeVA95+cAL0BkEcv9L+3JfLb7nus1NnjYSzUo5IHxc4KeSIDTSFkjOXNfhbRh6q6rWI9HXGU7cNv+re5TOj8e3JMlysasTa788hbeFY8ZwgCNiTa9oi4J7xIfgipxR5lQ0orm1CqJdTh2VRN+mhkEvhqJB1eL673j9YiD+nn8NtMX7419LEHls3h4h6RrdaWNavX4+IiAioVCokJSXh8OHD17z2nXfewdSpU+Hp6QlPT08kJydfdX1DQwNWrFiBkJAQODo6IjY2Fhs3buxO0YiGLMvAW+DqwAIAt8b4Y87ogG49WyaVYNmMaMwdY7rf0sJyrKgOmw4VAgBeumu0VauOhcpBhrUL4wAAnxwpwsmStvVb8qsaUVrXDIVMilfuHo3x5jrsv1DdYTnK1S2Y9touJP1pB/617yK0rT23pYBlsHLGuUp8e7Lj7isish+bA8uWLVuQmpqKNWvWIDs7G/Hx8ZgzZw4qKzveQG337t1YvHgxdu3ahczMTISGhmL27NkoLS0Vr0lNTUV6ejo2b96Ms2fP4umnn8aKFSvw1Vdfdb9mREOMh5NCHFtiGc/SW0b6u0IqMU1j1hsETB/hi6nDfa95/aRhXpifEARBMO1lZFnzZa95A8ZJw7zgpJBjSrTpGfvyrt59GgC+P1UGdbMempZW/OHbs5j0xwzM+/s+LPsoC+Xqlhuq08WqdgOIvzrd4cwmbasB7x8oQIXmxn4WEdnO5sDyxhtv4NFHH0VKSorYEuLk5IR33323w+s/+ugjLFu2DAkJCYiJicG//vUvGI1GZGRkiNccPHgQS5cuxYwZMxAREYHHHnsM8fHx1225IaKr/e3+cfjronhM/sk4lZ7mqJAhytc0qFcqAX73f6M6vef522Pg6CDD0UtX8NXxywAg7hg9fYQpqEwd4QMAOHChBoYO1m/Zftq0DkzyKH/4uiqhbtbj9GUNvjtZjo178ttdVy6u6tsVRqOAgmrTdga+rkpUN+jw6rbcq65770Ahfv/1Gfxl+9XniKh32RRYdDodsrKykJyc3PYAqRTJycnIzMzs0jOampqg1+vh5dU2U+Hmm2/GV199hdLSUgiCgF27duH8+fOYPXu2LcUjGvJGBrhiwbiQPhl/ER/qAQBYNDEUI7uwsWOgu6M4ePeP355FYXUjfiwwhYrpI02BJS7YHa4qudUmjRZXGnU4bJ6yvfqOWOz77Ux88+QUvGAOS18fvwy9wYiTJWo8tikLKe8dQbOua11G5ZoWtOiNkEslePVeU/dV+qlysSXI4mC+qbyWxfmuRxAEvLbtHDeKJOohNgWW6upqGAwG+Pv7Wx339/dHeXn5Ne6ytnLlSgQFBVmFnjfffBOxsbEICQmBQqHA3LlzsX79ekybNq3DZ2i1Wmg0GqsXEfWt38weid/fGYsX74jt8j2PTI1ElK8zKuu1mL/+AFr0RgS4qTDcPAVbLpPilihTK8u+89bdQjvPVcJgFBAT4IowbyeoHGQYE+yOh26JgLezAjWNOuzLq8K/9l8EADTrDTh6qdbqGZdqGjE5LQOvpp+zOm7pDgrzdsLkSG9IJaZp3FUNWvEag1FAtnmTyItVDVeFmZ86V16P9bvy8fuvTnPmEVEP6NNpzWvXrsUnn3yCzz//HCpV20yFN998E4cOHcJXX32FrKws/OUvf8Hy5cuxY8eODp+TlpYGd3d38RUaGtpXVSAiswB3FR66ZRicFF2fbKhykOHDXyYhyF0lTnGePsLXqkXI0i207ycDb7efMf1P0eyfDBx2kElxZ3wQAODtPRfx7Ym2AbMHLlh3C31ypBhl6hb8a3+B1RiVi+buoEgfF6gcZOJWBufataScLdOgwbzxY6POgAqNFtdzxrxGjVFo+/X1aFsN4lo3RHQ1mwKLj48PZDIZKioqrI5XVFQgIOD6sw9ef/11rF27Ftu3b0dcXJx4vLm5Gb/73e/wxhtv4M4770RcXBxWrFiBRYsW4fXXX+/wWatWrYJarRZfxcXFtlSDiOwo2MMRmx5JgrezAgBw2yg/q/NTzQNvsy9dgabFFGpa9AbsPW8KMLNjrVt4AWCBee2YHwtq0WoUoHIw/dN2ML8t9AiCgO/Ns390rUZ8fqxt4L+lhSXKvOt1jHmW1bnytqBhWUG47Z6G69az/V5Lp7qws/XKT0/gpj9l4HxF591NREORTYFFoVBgwoQJVgNmLQNoJ0+efM37Xn31VbzyyitIT09HYmKi1Tm9Xg+9Xg+p1LooMpkMRqMRHVEqlXBzc7N6EdHAEeXrgi+W34K3fj4Os34SQMK8nRDt54JWo4D0k6ZWlb3nq9CsNyDYwxGjg67++x4X4o5Ic9gAIHZTnSxVQ91kCj1ny+pRWNMkXvPJ4WKxW+eieXVdS8vKKPOYnPYtLEcKr1j9zPyfrMi793wVHvjXIRSbN5hs36pysvT6LSy6ViO+P1UOncGInec6nnHZk9JPleGWtTuvCmFE/ZnNXUKpqal455138MEHH+Ds2bN44okn0NjYiJSUFADAkiVLsGrVKvH6P//5z3jxxRfx7rvvIiIiAuXl5SgvL0dDg+n/Ttzc3DB9+nQ899xz2L17NwoKCvD+++/jww8/xIIFC3qomkTU34R6OeGOuKAOBwgvHG9qMfksuwQAsOnQJQCmbQE6ul4ikWBBgumeYT7OWDwxDFG+zhAE4JB5YO935taVyZHeUMqlyK2ox3HzmjCW1pJI88ynmABTKDpbbgosgiDgiPnLPd68km9+pXULy7od53HgQg3eP1gIQRCu28KibTXgn3vzcdq89svJ0jpoW03/g3a8uO6av2df5pRi8T8PobL+xqZVf5pVgtK6ZvxwtqLzi4n6CZsDi6WrZvXq1UhISEBOTg7S09PFgbhFRUUoK2vrQ96wYQN0Oh3uvfdeBAYGiq/23T2ffPIJJk6ciAceeACxsbFYu3Yt/vjHP+Lxxx/vgSoS0UBzd0IwJBJTF88PZyqwL68aUgmw9OaIa97zy6nD8Ktpkfjb/QmQSiW42Tx49+CFagiCIAaW+yeF4v/GBgIAthwpQovegNK6ZgAQW2liAk0tLBcq66FrNaK4thmV9Vo4yCRYOD4EQFurDACom/Vi+Nl7vgqX1S1QN+thyVZ5lfVWM5bW78rHn747h2e25AAw1dMi5xqBpdVgxCvfnEXmxRpszS7t8JqussxyutG1a4j6UreW5l+xYgVWrFjR4bndu3dbvS8sLOz0eQEBAXjvvfe6UxQiGoSCPBxxc5Q3DlyoEb/Ubx8TeM3l+gHASSHHqnbrwdwS7Y1Nhy7hQH4NzpRpcLG6EQq5FLfG+MHfTYXPj5Xiy5zLuDPOtKCdq0oujqsJ9nCEq1KOem0rLlY34JS5S2dssLu4inD7MSyZ+W3rxuRVNmCnueVipL8rqht0qG7Q4kyZBhPCPVGmbsY/95rWjDlf0YDzFfU43C6wlKlbUKFpuWoLhX151ag2z1o6WngFmG5aP+ZvGXkYFeiKuWMCu/R7q27SiwGtjIGFBhBufkhE/dLCcaaWDMvMnEemDrPp/psivSGRABcqGzDv7/sBANOG+8JV5YCkYV4YG+yOJp0Bz316AoCpO8jS3SSRSMRWlnNl9cg0r78ycZiX2ApTWteMFr2p1WT/Besp2O/sKwBg2sJgbLAp4Fi6hV5Lz0WLvm183pc5pcgyj49xNu+PdKyo7qr6fGruHgOA7KIrpn2Y8qrwt4w8PPvf49AbOh7z91Nn2w0kZgsLDSQMLETUL80dEwAn8xf4xAhPjGu3uWNXeDgpMCXaR3zv7azAw1MiAJgCyUvzRwOA2NoQ5eNsdb9lHMuXOaX4MsfUBTNjhB+8nRVwU8khCECBuVtoX55pNtIYczgpMg+8jQ10w9hg05iXk6Vq5BTXYat5dtLDt5gC2AcHL6Fe2wpXpRzz4kytJD/tFlI36fHDmQpz2U1rxFysbsTOs6YBuo06w3XHvrR3tsw6sHS2ngxRf8HAQkT9krNSjsWTwiCTSvDUbSO69Yx3liRi29PTcHzNbGS9OEsc1wKYdre+LzFEfN9+lhHQNo5lV24VWo0C5o4OwOQob0gkEnFw7sWqRhTVNOFSTRPkUgmemxNj9YzYIDeMDfEAABy4UI1HPjgCAFg4LhjPzBoOhVwqtiAlRnhiQrgplOUUm1pcimqaUK5uwTcnL0PXasRIf1ckmq/JKrxiNaPopxtG5hTX4da/7MbHh4usjrcPLDqDkWu/0IDRrTEsRER94Xf/Nwq/vm043B0dunW/ykF23W0DVs6NQfqpcmhaWhFtXm3XwtLCAgAuSjl+f9do8X2UrwtyiutwsaoBdc2mL/zxYZ64Jcobrio56ltMISQ20E3s/rGMF4kNdMOLd8TCVeWAGSN8sd3ccjJpmDcSQk1h5GSJGl/mlOLpLTkQBNNu2QBwz4Rg1DbqcaTwCj46XCS2DgHAwQs1eNq8gHh9ix4r/pONkivNWLfjPO5LDBWfca7cep2XMnULvF2UXfntJLIrtrAQUb8lk0q6HVa6wttFiX8/NBErZkbjtlHW68HEBLiKs3yenT0CAe5tg2AtrTGnL2uQfsq0VsyU4T6Qy6RiN1SwhyM8nBTwd1PC19UUCBJCPfDxozfB0zy419IFBJh2rI72c4GzQoZGnQHPmMMKYNoWwNFBhrsTgjExwhRqLF1AI/1NgSy76Aoaza01v//qDEqumMJMhUYrtr60GozINQcWy+8rx7HQQMEWFiIa0iZGeGFihNdVx52Vcvzu9lEo17RgyeQIq3OWFXHTT7ftoTZ1uCmozIr1x/enysXuHYlEglfmj8Hhglqkzh4BF2XbP7vJo/zh76aEg0yKscHukEkliAvxQObFGhgFYO7oALx+XzzOlWng6ayAn5sKE+TW/5/54ORwvL03H8W1zThcUIt6bSs+yy6BVAIkhnvhcGEtPs0qwfQRviisaYS21QhHBxkmRnhix9lKlGmuH1iqG7R4YnMWZsX647FpUV3/jSXqYQwsRETX8Oi0yA6Pjw3xgEImhc5gRKSPM+5NDEGCeffqBeOC4e7oIL4HTAOI5465evsSZ6Uc256eBolEAoU5iCRFeiHzYg3GhXlg3f0JUDnIkNguUHk4KRDt54IL5oXrZsb44fRlNT4+XIx/7b9omvIMYNmMaMwe7Y+73jqA7afLoWnR44x5/ZWRAa4I8nAEAJSrTS0xZ8s0kEslGO5v3YX23oECHCm8gvMVDXhkSiSk0t7fCZyoIwwsREQ2CvZwxHdPTYFRAIb7uVitviuRSK7qXroeDyeF1fvHpkVimI8zbo3xg8pB1uE9ieGeuFDZgJgAVwR7OOKWaB98fLhY3Ozx1hg/PJ08HDKpBMP9XJBX2YBvT5SJs5dGBbqJXVxl5kXuFv7jIPQGI177WRwWmKeUt+gN+Piwaa82dbMe58rrEdvB1ghEfYFjWIiIuiHazxUj/F073CrgRjgp5JifEAxX1bXH7vwsMQRuKjl+OcU0Nbr97Kexwe54c/E4yGVSSCQS3DPBFD7+sj0Xn2WZ1nKJDXRFoDmwlKtbcKzoCpr1BrQaBTyz5Tje3pMvrg7cfhbR4QLr3a/Plmlw55v7see89To0RL2BgYWIaICZEO6FE7+fg58lhgIAvJwVWDI5HInhnvj3Q4lwbjdOZuG4YDgpZKhu0KGy3rRS7tgQDwS4WbqEWpBtXqjOstJv2vfn8Jv/ncD7BwsBAP5upkHD7bcQAIANu/NxslSNd/Ze7LW6ElmwS4iIaBB4ef6YDo/7uamQ8ex0nChRo7i2CZ5OCiSEeqDQvOhdmboF2ZdM416enjUCWr0Bf/rurLjxpEImxUt3jcHjm7NwuKAWgiBAIpGgRW8Q14E5eqkWulYjFHIpqhu0aNYZxG0UmnUGbNh9AXclBCHa79pTzIk6w8BCRDTIBbo7ItDd0eqYZQxLs96Aw+adqCeEeSI2yA2xgW5Y8fEx1DbqcEd8IGbG+EIpl6KmUYf8qgZE+7lif161uOhdi96I4yV1GBfqgXs2HERVvRa7fjMD/m4qvH+wEH/feQH5VY1Y/8D4vq04DSrsEiIiGoJUDjJ4OpnGyehajXBWtC2yd3O0D7799RS8PH80XrprNJRyGcabt0Y4dNEUbr47VWb1vEP5NTiYX4NLNU1o0hmwJ9c0rsWyz1LxlaY+qRcNXgwsRERDVEC7Vpf4UA9xNVzA1CqzZHKEOPg3KdI0tfrHAlP3zw7zCr13xgcBAA4V1ODLnMvi/XvzqtCiN4jTrCs6We+FqDMMLEREQ1Rgu9V7x3eyuWTSMG8AwMEL1Xhn30VoWlrh66rEipnRAICjhVewrd1CevsvVONo4RVoW01bE1TVa9HaxR2liTrCwEJENES1327AsjLvtYwL84CTQoaaRh1e25YLwLQS7wh/F/i4KKBtNaJB24ogdxVclXLUNenx9t588X6jANRwo0W6AQwsRERDVKBbW2AZF+Zx3WtVDjJ89EgSFk8KhY+LEgqZFIsmhkIikSAp0lu87q6EYNwcbXq/L896B2nuW0Q3grOEiIiGKEsLS6Sv81Ur7nZkXJgnxoV54o93C2g1CuJ2AjdFeuPbE6ZBuHePC8KRwivYdrqi7ee4qVCuaeE4FrohDCxEREPUrTF+mDrcBwvHB9t0n1QqgaLdAN2ZI33hpJBhTLA7YgLc4NhuS4FIH2dE+7mg/AwDC90YBhYioiHK20WJTb9MuuHnhHg6Yf/KW6FyMLW4hHs7I8zLCUW1Tbg52htS8/YFFRrtDf8sGro4hoWIiG6Yl7MCToq2/wd+ICkMCrkU94wPgb95rEw5W1joBrCFhYiIetyvpkfhV9OjAAD5VaZtANglRDeCLSxERNSrLJsnMrDQjWBgISKiXhVg7hLiGBa6EQwsRETUq/zMgUXdrEeL3mDn0tBAxcBCRES9yk0lF6c6s1uIuouBhYiIepVEIhHHsXC1W+ouBhYiIup1lm6hinqOY6HuYWAhIqJeJw68ZQsLdRMDCxER9TpObaYbxcBCRES9rv1qt+omPYpqmuxcIhpoGFiIiKjXWQLLkcJaTHttF2b+ZTdK65rtXCoaSBhYiIio1wW4ty0ep27Ww2AUcLpUbedS0UDCwEJERL0uwtsZcqkEcqlEHIBbfIUtLNR13PyQiIh6na+rEp8vuwUuKjk+OVKEt/dcRHEtx7FQ1zGwEBFRnxgb4g4ACPNyAgAGFrIJu4SIiKhPhXqaA8sVBhbqOgYWIiLqU6FiC0szBEGwc2looGBgISKiPhXs4QiJBGjWG1DdoLN3cWiAYGAhIqI+pZBLESjOFGK3EHUNAwsREfW5EA68JRt1K7CsX78eERERUKlUSEpKwuHDh6957TvvvIOpU6fC09MTnp6eSE5O7vD6s2fP4q677oK7uzucnZ0xceJEFBUVdad4RETUz3GmENnK5sCyZcsWpKamYs2aNcjOzkZ8fDzmzJmDysrKDq/fvXs3Fi9ejF27diEzMxOhoaGYPXs2SktLxWvy8/MxZcoUxMTEYPfu3Thx4gRefPFFqFSq7teMiIj6LXGmUC0Xj6OukQg2DtFOSkrCxIkT8dZbbwEAjEYjQkND8eSTT+L555/v9H6DwQBPT0+89dZbWLJkCQDg/vvvh4ODAzZt2tSNKgAajQbu7u5Qq9Vwc3Pr1jOIiKjvbM0uQep/j+PmKG/859Gb7F0cshNbvr9tamHR6XTIyspCcnJy2wOkUiQnJyMzM7NLz2hqaoJer4eXlxcAU+D59ttvMWLECMyZMwd+fn5ISkrCF198cc1naLVaaDQaqxcREQ0cli6hInYJURfZFFiqq6thMBjg7+9vddzf3x/l5eVdesbKlSsRFBQkhp7Kyko0NDRg7dq1mDt3LrZv344FCxZg4cKF2LNnT4fPSEtLg7u7u/gKDQ21pRpERGRnlrVYytQtaDUY++RnqptMmy7SwNSns4TWrl2LTz75BJ9//rk4PsVoNP1BnT9/Pp555hkkJCTg+eefxx133IGNGzd2+JxVq1ZBrVaLr+Li4j6rAxER3ThfFyUUcikMRgFl6hbxePqpcuw9X9XjP+/ghWrEv7wdb+280OPPpr5hU2Dx8fGBTCZDRUWF1fGKigoEBARc997XX38da9euxfbt2xEXF2f1TLlcjtjYWKvrR40adc1ZQkqlEm5ublYvIiIaOKRSCUI9HQG0dQsdLqjF45uz8OiHR9GiN9j0vAZt63XPbz9j+t76/lRZN0pL/YFNgUWhUGDChAnIyMgQjxmNRmRkZGDy5MnXvO/VV1/FK6+8gvT0dCQmJl71zIkTJyI3N9fq+Pnz5xEeHm5L8YiIaACxdAvlVdTDaBTwx2/PAAC0rUZcrGrs0jOMRgGvfHMGY3+/Df/Yfe3WkzOXTWMdz1fUo0l3/XBD/ZPNuzWnpqZi6dKlSExMxKRJk7Bu3To0NjYiJSUFALBkyRIEBwcjLS0NAPDnP/8Zq1evxn/+8x9ERESIY11cXFzg4uICAHjuueewaNEiTJs2DTNnzkR6ejq+/vpr7N69u4eqSURE/U1CqAd251bh1W25KFO34HiJWjx3oaoBsUHXbz3XtRrx3KfH8WXOZQDA33bkYeG4EAS4Wy+JYTQKOFNmCixGATh9WYOJEV49XBvqbTaPYVm0aBFef/11rF69GgkJCcjJyUF6ero4ELeoqAhlZW1Nbhs2bIBOp8O9996LwMBA8fX666+L1yxYsAAbN27Eq6++irFjx+Jf//oXPvvsM0yZMqUHqkhERP3R49OjMCXaB006A97eexEA4KyQAQAuVNRf915dqxFPbM7ClzmXIZdKEOblBG2rEX/LOH/VtUW1TVZdRseL63quEtRnbF6HpT/iOixERANTk64VD/77MLIuXUGAmwq/uCkMr28/j9vHBGDDLyYAADQteripHMR79AYjln+Uje1nKqCUS7HxwQlwVcpx78ZMyKQSbH9mGiJ9nAEAEokE354ow/L/ZIv33xkfhDcXj+vbilKHem0dFiIiop7kpJDj3YcmYsXMaPzjF+MxNsQDAJBX2QAA+ORwEeJ+vx1//PYMBEGAttWAX398DNvPVEAhl+JfSxMxc6QfEiO8kDzKDwajgLnr9iLqd99h9l/3okHbitOXTV1NoV6mQb4nSupuuNxGo4D7/5mJu97ajyuNg3/H6fcOFOBkiRr2bOOweQwLERFRT3J3dMBv5owEAFyuMy3VX1jdCL3BiC9yTNu4vLOvAK1GAadLNThcWAuFTIq3H5yAqcN9xeesnBuD/Req0aI3LZeRV9mAr3Iu47R5wO2ixFC8vv08LtU0oa5JBw8nRbfLnFV0BYcu1gIAlv8nGx88PAkOMus2AL3BiMc3ZeFKkw4fP3YTlHJZt3+ePZVcacJLX5sGRGeuuhWB7o52KQdbWIiIqN8IdFfBWSFDq1HA2TINsi5dEc+9d6AQhwtr4aqU472UiZg50s/q3uH+rsh8/jbsfW4mUmeNAAB8cqRIDCyTo3wQ4W2amdR+gG9X5JbX49cfH8PFKlPLz/cn2xZLPZhfg5e+Pn3VPRt25yPjXCWyi+pwrKjOpp/Xn3yebQqNkyO97RZWAAYWIiLqRyQSCaL9TDNI//NjEfQGAcEejlh9h2mtrmAPR3y27GbcEu3T4f2ezgqEeTvhFzeFQyGT4kSJGtUNWkgkwKhAV8SZu5xO2DDwVhAE/PbT4/jq+GWs+eo0BEHAttOmwLJ4UhgkEmDzoSIczK8W7zl9WY2/Z+SJ79sHr4FEEARsPWYKLPdMCLFrWRhYiIioX4n2cwUAfG7+opwS7YOHpwzDzmen44fUaRjh79rpM7ycFZgzpm1B00gfZzgp5IgP9QBgWwtLxtlK8fp9edXYfOgSSuua4aSQYc2dsVgwLhgAsMe8Qq+u1Yhn/3scrUYBrirTyItsGwPLtcaK6A1GHC+u67OxJNlFdSioboSjgwxzx1x/gdjexsBCRET9ynB/UwuLttU0FmXKcFNrSqSvC5wUXR96uXhS2z5zo4PcAQDxIab/ZhddgbbVtJrukcJa/PL9I3hrZx7yKuqtwoDRKOCNH0xTpV2Vpp9tGc8xM8YPKgcZpprLZxnTsiu3EufK6+Hp5IB1ixIAmMa8CIKAY0VXMPGPO/DfI9feUibr0hXE/X473mzXQmOxYXc+5q8/IJapvdzyerzxw3ls2J2Pz7JKbF4tuCNbs0sAALePCYCL0r7DXjnoloiI+pVoXxer9zdHeXfrOZMjvRHh7YTCmiaMNi9CFxfiAX83JSo0WnyZcxkLxwXjuf8dR2FNEzLOVeL17efhppJjuL8rhvu5QCmX4kyZBi5KOd5/eCLu3ZiJVvMGinNHm1ockoaZyneqVI36Fj12mLcBuHtcMKYO94VSLkVdkx4Xqxvxj935qKrX4tPsEtw38eqNewVBwMtfn0a9thUf/ViEFbdGQyKRiOfTT5m6ot7ecxH3JYaKqwUDwMrPTiCnXVfX1mMl+CBlEuSy7rVNtOgN+Pq4aVG+hePt2x0EsIWFiIj6GUsLCwCMDnKDt4uyW8+RSCRYe08c5icEYZE5HCjkUqTcMgwA8M7ei9iaXYrCmiZ4Ojlg5khfKGRSaFpakXXpCj45UowPMi8BAB6+JQITwr1wu7lbRCGXYmaMadBvkIcjwr2dYDAKOFxQi53nKgEAs0b5QyGXIt48bmb76QrsMp/LLa/vsFvn+1PlYvdTuaYF+e22KKht1Ikr9uoMRqz9/px4rkVvEKdv3xkfBCeFDAcu1OC17dbb3thi17lKaFpaEeiuwuRuhsaexBYWIiLqV0I8naCUS6FtNWLKNQbXdtVNkd64KdL6y/bnSWF4a+cF5FU24Pfm2T3LZkTj0WmR0LYaUFDdiLyKBuRVNiCvoh5ymRSPTosEADydPAL786px97hgqy6Sm4Z541JNEzbuyUdNow6uKjkmDjMt/z8+3BOHC2uxftcFsXVG3axHhUZrtY2A3mDE69tMAUMmlcBgFLA/r0ochJyZXwMA8HVVoqZBi29PluGhwlpMjPDCufJ66A0CvJwV+Pv9Cfj2ZBlW/OcY3t5zEQkhHrh9bKDNv3ffnjStWn9XfBBkUkknV/c+trAQEVG/IpNKxMGxt43y7/Hnu6kccL+5xaVJZ4CvqxK/uMm02a5SLkNMgBvujA9C6qwR2PCLCXhz8Ti4mlfaHeHvipzVs/Hy/DFWz7wpyhROjhSaBtfOHOknrssyIdwTwNU7Sp8r11i9/9/RElysboS3swKPTzcFpP0XasTz+y+YZiHdGReERRPDAADrdpjGslgWwxsb7A6JRII74oLw6FRTS1JXW1kMRgF6g2ncUIveILYU/V83wk5vYGAhIqJ+52/3J+CTx27CpGG9s0nhw1OGQW5uNVg2IwqOiq4v6ibtoLXBMo7FIjm2LWhZAgsAKGRSsdUot7xtvySjUcDbe/NN5ZkZjbmjTSHh0MUatJpDhGXa9C3R3nhiepT5fC3UzXocLzZ1B1kGFQPAEzOiAQAXqxpR36K/bp1a9Ab8bONBTE7LQGldM3bnVqFJZ0CwhyPi2j3TnhhYiIio3wl0d7yqK6cnBXk44qX5o/GLm8Lw86SwHnleuHlROrlUgukj2lbg9XJWiHsbzRrtL4aw9oFl57lKXKppgptKjsWTQjE6yA0eTg5o0LbieEkdSq404VJNE2RSCSYN80KYtxOifJ1hMArYl1eFk6V1ACCuM2P5uYHmLqdz5dabSZ4qVWPm67vxtx15MBoFvPT1GWQX1aG6QYeXvz6N78zdQf83NsBq0K89cQwLERENSQ8khffo8yzjWJIiveDu6GB17p4JIXhr5wU8MmUYKuu1AKxDxLsHCgAAi5PCxKnbt0T54NuTZdifVyMGj4RQD7F76tYYP+RXFeCb42W4YN576aetIbGBbihTt+B0qRoTI9paqzYfuoSC6kb8dcd5ZJyrwIkSNSQSQCqRYNvpCrH1qb90BwFsYSEiIuoRD08ZhsRwTzx124irzi2fGY0zL8/BuDBPxASYFr67UNWAVoMRZ8s0OJhfA5lUgiWTI8R7LKv5/vdoMTaau4tuaTdbxzJLaduZchgFIMBNBT+3tkG8AMTp3JbZRYBp6vSu3Erx/QnzrKQnbx2OlJtNP7/VKCDIXYUE81ii/oAtLERERD1gZIArPn3i5muet3SthHo6wUkhQ5POgMKaRry739S6MndMAII92vbqmTrcBxIJUGreEBIAZsS07Z80McILrko56s2DeTsaaxJrDiyW/ZQsv67QaOGkkOG9hybixS9PYWSAG566bTia9QZ8feIyKjRa3D42sN90BwEMLERERH1KKpVguL8rjhfX4bPsUnGvnofN68NYhHo54Z8PJuJ8RT1UDjJE+jhjfFjbAF4HmRRTR/jgO/NGjPEdtIZYVvjNq2iArtUIhVwqrgVzS7QPkiK9sf2Z6eL1Lko51v98PD7MvIRfmady9xcMLERERH0sxhxYNuw2dfXcERdoNZvIYlasP2bFXntq98yRfmJg6aiFJcTTEa4qOepbWpFf1YBRgW5id9BPd7u2SIzwQmJE78zOuhEcw0JERNTHRga0beDo7uiANXeO7tZzZoz0g1wqgUImRVywx1XnJRIJYgPbuoVqG3U4Zl6+f2aM71XX92dsYSEiIupjMe0Cy4t3xMLXtXvbD/i6KvFeykQAgLuTQ4fXxAa54ceCWpy5rIFMCggCMCrQDYHujh1e318xsBAREfWx8eGeSBrmhWE+zrhnfPANPWvq8Ou3lFjGsey/UIV9eVUAgJkjB1brCsDAQkRE1OdUDjJs+dXkPvlZli6h8xWmtVo8nRxw/8QbXyyvr3EMCxER0SA23N8FTuatB6YO98G2p6chzLwq70DCFhYiIqJBzEEmxTtLElFVr8Vd8UEd7oU0EDCwEBERDXKWVXMHMnYJERERUb/HwEJERET9HgMLERER9XsMLERERNTvMbAQERFRv8fAQkRERP0eAwsRERH1ewwsRERE1O8xsBAREVG/x8BCRERE/R4DCxEREfV7DCxERETU7zGwEBERUb83KHZrFgQBAKDRaOxcEiIiIuoqy/e25Xv8egZFYKmvrwcAhIaG2rkkREREZKv6+nq4u7tf9xqJ0JVY088ZjUZcvnwZrq6ukEgkPfpsjUaD0NBQFBcXw83NrUef3V8M9joO9voBrONgMNjrB7COg0FP108QBNTX1yMoKAhS6fVHqQyKFhapVIqQkJBe/Rlubm6D8g9fe4O9joO9fgDrOBgM9voBrONg0JP166xlxYKDbomIiKjfY2AhIiKifo+BpRNKpRJr1qyBUqm0d1F6zWCv42CvH8A6DgaDvX4A6zgY2LN+g2LQLREREQ1ubGEhIiKifo+BhYiIiPo9BhYiIiLq9xhYiIiIqN9jYOnE+vXrERERAZVKhaSkJBw+fNjeReqWtLQ0TJw4Ea6urvDz88Pdd9+N3Nxcq2tmzJgBiURi9Xr88cftVGLb/f73v7+q/DExMeL5lpYWLF++HN7e3nBxccE999yDiooKO5bYNhEREVfVTyKRYPny5QAG5ue3d+9e3HnnnQgKCoJEIsEXX3xhdV4QBKxevRqBgYFwdHREcnIy8vLyrK6pra3FAw88ADc3N3h4eOCXv/wlGhoa+rAW13e9Our1eqxcuRJjx46Fs7MzgoKCsGTJEly+fNnqGR199mvXru3jmnSss8/woYceuqrsc+fOtbpmIH+GADr8eymRSPDaa6+J1/Tnz7Ar3w9d+fezqKgI8+bNg5OTE/z8/PDcc8+htbW1x8rJwHIdW7ZsQWpqKtasWYPs7GzEx8djzpw5qKystHfRbLZnzx4sX74chw4dwg8//AC9Xo/Zs2ejsbHR6rpHH30UZWVl4uvVV1+1U4m7Z/To0Vbl379/v3jumWeewddff43//e9/2LNnDy5fvoyFCxfasbS2OXLkiFXdfvjhBwDAz372M/Gagfb5NTY2Ij4+HuvXr+/w/Kuvvoq///3v2LhxI3788Uc4Oztjzpw5aGlpEa954IEHcPr0afzwww/45ptvsHfvXjz22GN9VYVOXa+OTU1NyM7Oxosvvojs7Gxs3boVubm5uOuuu6669uWXX7b6bJ988sm+KH6nOvsMAWDu3LlWZf/444+tzg/kzxCAVd3Kysrw7rvvQiKR4J577rG6rr9+hl35fujs30+DwYB58+ZBp9Ph4MGD+OCDD/D+++9j9erVPVdQga5p0qRJwvLly8X3BoNBCAoKEtLS0uxYqp5RWVkpABD27NkjHps+fbrw1FNP2a9QN2jNmjVCfHx8h+fq6uoEBwcH4X//+5947OzZswIAITMzs49K2LOeeuopISoqSjAajYIgDPzPD4Dw+eefi++NRqMQEBAgvPbaa+Kxuro6QalUCh9//LEgCIJw5swZAYBw5MgR8Zrvv/9ekEgkQmlpaZ+Vvat+WseOHD58WAAgXLp0STwWHh4u/PWvf+3dwvWAjuq3dOlSYf78+de8ZzB+hvPnzxduvfVWq2MD5TMUhKu/H7ry7+d3330nSKVSoby8XLxmw4YNgpubm6DVanukXGxhuQadToesrCwkJyeLx6RSKZKTk5GZmWnHkvUMtVoNAPDy8rI6/tFHH8HHxwdjxozBqlWr0NTUZI/idVteXh6CgoIQGRmJBx54AEVFRQCArKws6PV6q88zJiYGYWFhA/Lz1Ol02Lx5Mx5++GGrDT8H+ufXXkFBAcrLy60+M3d3dyQlJYmfWWZmJjw8PJCYmChek5ycDKlUih9//LHPy9wT1Go1JBIJPDw8rI6vXbsW3t7eGDduHF577bUebWrvbbt374afnx9GjhyJJ554AjU1NeK5wfYZVlRU4Ntvv8Uvf/nLq84NlM/wp98PXfn3MzMzE2PHjoW/v794zZw5c6DRaHD69OkeKdeg2PywN1RXV8NgMFj95gOAv78/zp07Z6dS9Qyj0Yinn34at9xyC8aMGSMe//nPf47w8HAEBQXhxIkTWLlyJXJzc7F161Y7lrbrkpKS8P7772PkyJEoKyvDSy+9hKlTp+LUqVMoLy+HQqG46kvA398f5eXl9inwDfjiiy9QV1eHhx56SDw20D+/n7J8Lh39HbScKy8vh5+fn9V5uVwOLy+vAfm5trS0YOXKlVi8eLHVxnK//vWvMX78eHh5eeHgwYNYtWoVysrK8MYbb9ixtF0zd+5cLFy4EMOGDUN+fj5+97vf4fbbb0dmZiZkMtmg+ww/+OADuLq6XtXdPFA+w46+H7ry72d5eXmHf1ct53oCA8sQtHz5cpw6dcpqfAcAqz7jsWPHIjAwELfddhvy8/MRFRXV18W02e233y7+Oi4uDklJSQgPD8d///tfODo62rFkPe/f//43br/9dgQFBYnHBvrnN9Tp9Xrcd999EAQBGzZssDqXmpoq/jouLg4KhQK/+tWvkJaW1u+XgL///vvFX48dOxZxcXGIiorC7t27cdttt9mxZL3j3XffxQMPPACVSmV1fKB8htf6fugP2CV0DT4+PpDJZFeNgq6oqEBAQICdSnXjVqxYgW+++Qa7du1CSEjIda9NSkoCAFy4cKEvitbjPDw8MGLECFy4cAEBAQHQ6XSoq6uzumYgfp6XLl3Cjh078Mgjj1z3uoH++Vk+l+v9HQwICLhqEHxraytqa2sH1OdqCSuXLl3CDz/8YNW60pGkpCS0traisLCwbwrYgyIjI+Hj4yP+uRwsnyEA7Nu3D7m5uZ3+3QT652d4re+Hrvz7GRAQ0OHfVcu5nsDAcg0KhQITJkxARkaGeMxoNCIjIwOTJ0+2Y8m6RxAErFixAp9//jl27tyJYcOGdXpPTk4OACAwMLCXS9c7GhoakJ+fj8DAQEyYMAEODg5Wn2dubi6KiooG3Of53nvvwc/PD/PmzbvudQP98xs2bBgCAgKsPjONRoMff/xR/MwmT56Muro6ZGVlidfs3LkTRqNRDGz9nSWs5OXlYceOHfD29u70npycHEil0qu6UgaCkpIS1NTUiH8uB8NnaPHvf/8bEyZMQHx8fKfX9qfPsLPvh678+zl58mScPHnSKnxawndsbGyPFZSu4ZNPPhGUSqXw/vvvC2fOnBEee+wxwcPDw2oU9EDxxBNPCO7u7sLu3buFsrIy8dXU1CQIgiBcuHBBePnll4WjR48KBQUFwpdffilERkYK06ZNs3PJu+7ZZ58Vdu/eLRQUFAgHDhwQkpOTBR8fH6GyslIQBEF4/PHHhbCwMGHnzp3C0aNHhcmTJwuTJ0+2c6ltYzAYhLCwMGHlypVWxwfq51dfXy8cO3ZMOHbsmABAeOONN4Rjx46JM2TWrl0reHh4CF9++aVw4sQJYf78+cKwYcOE5uZm8Rlz584Vxo0bJ/z444/C/v37heHDhwuLFy+2V5Wucr066nQ64a677hJCQkKEnJwcq7+blpkVBw8eFP76178KOTk5Qn5+vrB582bB19dXWLJkiZ1rZnK9+tXX1wu/+c1vhMzMTKGgoEDYsWOHMH78eGH48OFCS0uL+IyB/BlaqNVqwcnJSdiwYcNV9/f3z7Cz7wdB6Pzfz9bWVmHMmDHC7NmzhZycHCE9PV3w9fUVVq1a1WPlZGDpxJtvvimEhYUJCoVCmDRpknDo0CF7F6lbAHT4eu+99wRBEISioiJh2rRpgpeXl6BUKoXo6GjhueeeE9RqtX0LboNFixYJgYGBgkKhEIKDg4VFixYJFy5cEM83NzcLy5YtEzw9PQUnJydhwYIFQllZmR1LbLtt27YJAITc3Fyr4wP189u1a1eHfy6XLl0qCIJpavOLL74o+Pv7C0qlUrjtttuuqntNTY2wePFiwcXFRXBzcxNSUlKE+vp6O9SmY9erY0FBwTX/bu7atUsQBEHIysoSkpKSBHd3d0GlUgmjRo0S/vSnP1l94dvT9erX1NQkzJ49W/D19RUcHByE8PBw4dFHH73qf/oG8mdo8fbbbwuOjo5CXV3dVff398+ws+8HQejav5+FhYXC7bffLjg6Ogo+Pj7Cs88+K+j1+h4rp8RcWCIiIqJ+i2NYiIiIqN9jYCEiIqJ+j4GFiIiI+j0GFiIiIur3GFiIiIio32NgISIion6PgYWIiIj6PQYWIiIi6vcYWIiIiKjfY2AhIiKifo+BhYiIiPo9BhYiIiLq9/4/38QbOrnMjokAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ehknU7xtbHwz"
      },
      "outputs": [],
      "source": [
        "# put layers into eval mode (needed for batchnorm especially)\n",
        "for layer in model.layers:\n",
        "  layer.training = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W1wFpKubHwz",
        "outputId": "1e61dc2a-d568-4a76-b64f-0d7b1acd162e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.7690281867980957\n",
            "val 1.9936515092849731\n"
          ]
        }
      ],
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQdB3cZYbHw0"
      },
      "source": [
        "### performance log\n",
        "\n",
        "- original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n",
        "- context: 3 -> 8 (22K params): train 1.918, val 2.027\n",
        "- flat -> hierarchical (22K params): train 1.941, val 2.029\n",
        "- fix bug in batchnorm: train 1.912, val 2.022\n",
        "- scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.769, val 1.993\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "CSE5ZEgebHw0",
        "outputId": "0fd1b55e-e6b0-4eeb-86e8-a96cc37d2b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aiyanah.\n",
            "giusopf.\n",
            "lorron.\n",
            "roger.\n",
            "rhyitte.\n",
            "christell.\n",
            "jedmccee.\n",
            "kelipson.\n",
            "briyah.\n",
            "sylot.\n",
            "zennica.\n",
            "mythan.\n",
            "daxphon.\n",
            "petrit.\n",
            "adalie.\n",
            "jeniyah.\n",
            "glatipe.\n",
            "manaswi.\n",
            "yeslee.\n",
            "stephania.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      logits = model(torch.tensor([context]))\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w054JOpbHw1"
      },
      "source": [
        "### Next time:\n",
        "Why convolutions? Brief preview/hint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBP4pbSnbHw1",
        "outputId": "5dc847b5-d40b-4e6a-f25b-55eedc770b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "........ --> d\n",
            ".......d --> i\n",
            "......di --> o\n",
            ".....dio --> n\n",
            "....dion --> d\n",
            "...diond --> r\n",
            "..diondr --> e\n",
            ".diondre --> .\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[7:15], Ytr[7:15]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhUwWXX8bHw2",
        "outputId": "9d5d20ce-180c-4178-fd22-3e7a7dcc38ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 27])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward a single example:\n",
        "logits = model(Xtr[[7]])\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBDyYGUWbHw2",
        "outputId": "f288231e-6a20-4940-845f-596944950912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 27])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward all of them\n",
        "logits = torch.zeros(8, 27)\n",
        "for i in range(8):\n",
        "  logits[i] = model(Xtr[[7+i]])\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCoo_TvZbHw3"
      },
      "outputs": [],
      "source": [
        "# convolution is a \"for loop\"\n",
        "# allows us to forward Linear layers efficiently over space"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}